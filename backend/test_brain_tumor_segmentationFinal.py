#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script professionnel de segmentation de tumeurs c√©r√©brales
Syst√®me d'aide au diagnostic m√©dical utilisant U-Net pour la segmentation
automatique des tumeurs c√©r√©brales sur images IRM multimodales.

Auteur: [Votre nom]
Version: 2.1 - Version corrig√©e
Date: 2025
"""

import os
import numpy as np
import nibabel as nib
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize
from matplotlib.gridspec import GridSpec
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# TensorFlow imports avec gestion d'erreur
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    from tensorflow.keras import backend as K
    TENSORFLOW_AVAILABLE = True
    print("‚úÖ TensorFlow disponible")
except ImportError:
    print("‚ö†Ô∏è TensorFlow non disponible - mode simulation uniquement")
    TENSORFLOW_AVAILABLE = False
    # Cr√©er des substituts pour les fonctions TensorFlow
    class K:
        @staticmethod
        def flatten(x): return np.flatten(x)
        @staticmethod
        def sum(x): return np.sum(x)
        @staticmethod
        def square(x): return np.square(x)
        @staticmethod
        def abs(x): return np.abs(x)
        @staticmethod
        def round(x): return np.round(x)
        @staticmethod
        def clip(x, min_val, max_val): return np.clip(x, min_val, max_val)
        @staticmethod
        def epsilon(): return 1e-7

# Configuration pour g√©n√©ration d'images haute qualit√©
import matplotlib
matplotlib.use('Agg')
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 11

# ================================================================================
# CONSTANTES ET CONFIGURATION
# ================================================================================

IMG_SIZE = 128
VOLUME_SLICES = 100
VOLUME_START_AT = 22

# Classification m√©dicale des r√©gions tumorales selon BraTS
TUMOR_CLASSES = {
    0: {'name': 'Tissu sain', 'abbr': 'Normal', 'color': '#000000', 'alpha': 0.0},
    1: {'name': 'Noyau n√©crotique/kystique', 'abbr': 'Necrotic Core', 'color': '#FF0000', 'alpha': 0.8},
    2: {'name': '≈íd√®me p√©ritumoral', 'abbr': 'Peritumoral Edema', 'color': '#00FF00', 'alpha': 0.7},
    3: {'name': 'Tumeur rehauss√©e', 'abbr': 'Enhancing Tumor', 'color': '#0080FF', 'alpha': 0.9}
}

# Modalit√©s IRM et leurs caract√©ristiques
MRI_MODALITIES = {
    'T1': {'name': 'T1-weighted', 'description': 'Anatomie structurelle', 'cmap': 'gray'},
    'T1CE': {'name': 'T1-weighted + Gadolinium', 'description': 'Rehaussement tumoral', 'cmap': 'gray'},
    'T2': {'name': 'T2-weighted', 'description': '≈íd√®me et liquides', 'cmap': 'gray'},
    'FLAIR': {'name': 'FLAIR', 'description': 'Suppression du LCR', 'cmap': 'gray'}
}

# ================================================================================
# M√âTRIQUES M√âDICALES SP√âCIALIS√âES
# ================================================================================

def dice_coef(y_true, y_pred, smooth=1.0):
    """Coefficient de Dice - M√©trique standard en segmentation m√©dicale"""
    class_num = 4
    total_loss = 0
    for i in range(class_num):
        y_true_f = K.flatten(y_true[:,:,:,i])
        y_pred_f = K.flatten(y_pred[:,:,:,i])
        intersection = K.sum(y_true_f * y_pred_f)
        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))
        total_loss += loss
    return total_loss / class_num

def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):
    """Dice pour r√©gion n√©crotique - Critique pour planification chirurgicale"""
    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)

def dice_coef_edema(y_true, y_pred, epsilon=1e-6):
    """Dice pour ≈ìd√®me - Important pour √©valuation de l'effet de masse"""
    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)

def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):
    """Dice pour tumeur rehauss√©e - Cible th√©rapeutique principale"""
    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)

def precision(y_true, y_pred):
    """Pr√©cision - Minimise les faux positifs"""
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    return true_positives / (predicted_positives + K.epsilon())

def sensitivity(y_true, y_pred):
    """Sensibilit√©/Recall - Minimise les faux n√©gatifs (critique en m√©dical)"""
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())

def specificity(y_true, y_pred):
    """Sp√©cificit√© - Capacit√© √† identifier les tissus sains"""
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

# ================================================================================
# SIMULATION POUR MODE SANS MOD√àLE
# ================================================================================

def simulate_segmentation_predictions(preprocessed_data):
    """
    Simule des pr√©dictions de segmentation r√©alistes quand le mod√®le n'est pas disponible
    """
    batch_size, height, width, channels = preprocessed_data.shape

    # Cr√©er des pr√©dictions factices avec 4 classes (fond + 3 classes tumorales)
    predictions = np.zeros((batch_size, height, width, 4))

    for i in range(batch_size):
        # Utiliser les donn√©es d'entr√©e pour cr√©er une segmentation r√©aliste
        flair_slice = preprocessed_data[i, :, :, 0]
        t1ce_slice = preprocessed_data[i, :, :, 1]

        # Combiner les modalit√©s
        combined = (flair_slice + t1ce_slice) / 2

        # Cr√©er des seuils adaptatifs
        mean_val = np.mean(combined)
        std_val = np.std(combined)

        # Classe 0: Fond (tissu sain)
        background_mask = combined < (mean_val + 0.5 * std_val)
        predictions[i, :, :, 0][background_mask] = 0.9

        # Classe 1: Noyau n√©crotique (zones de faible intensit√© dans la tumeur)
        necrotic_mask = (combined >= (mean_val + 0.5 * std_val)) & (combined < (mean_val + 1.0 * std_val))
        predictions[i, :, :, 1][necrotic_mask] = 0.8

        # Classe 2: ≈íd√®me p√©ritumoral (zones d'intensit√© moyenne)
        edema_mask = (combined >= (mean_val + 1.0 * std_val)) & (combined < (mean_val + 1.5 * std_val))
        predictions[i, :, :, 2][edema_mask] = 0.7

        # Classe 3: Tumeur rehauss√©e (zones de haute intensit√©)
        enhancing_mask = combined >= (mean_val + 1.5 * std_val)
        predictions[i, :, :, 3][enhancing_mask] = 0.9

        # Normaliser pour que la somme des probabilit√©s = 1
        for h in range(height):
            for w in range(width):
                pixel_sum = np.sum(predictions[i, h, w, :])
                if pixel_sum > 0:
                    predictions[i, h, w, :] /= pixel_sum
                else:
                    predictions[i, h, w, 0] = 1.0  # Fond par d√©faut

    return predictions

# ================================================================================
# TRAITEMENT ET PR√âPARATION DES DONN√âES
# ================================================================================

def load_and_preprocess_case(case_path):
    """
    Charge et pr√©traite un cas m√©dical complet avec validation qualit√©.

    Args:
        case_path: Chemin vers le dossier patient

    Returns:
        Donn√©es pr√©trait√©es et m√©tadonn√©es m√©dicales
    """
    print(f"  üìÅ Chargement du cas: {os.path.basename(case_path)}")

    # Identification automatique des modalit√©s
    files = [f for f in os.listdir(case_path) if f.endswith('.nii')]

    modality_paths = {}
    for file in files:
        file_lower = file.lower()
        if 'flair' in file_lower:
            modality_paths['flair'] = os.path.join(case_path, file)
        elif file_lower == 't1.nii' or ('_t1.' in file_lower and 't1ce' not in file_lower):
            modality_paths['t1'] = os.path.join(case_path, file)
        elif 't1ce' in file_lower:
            modality_paths['t1ce'] = os.path.join(case_path, file)
        elif file_lower == 't2.nii' or '_t2.' in file_lower:
            modality_paths['t2'] = os.path.join(case_path, file)

    # Validation de la pr√©sence de toutes les modalit√©s
    required_modalities = ['flair', 't1', 't1ce', 't2']
    missing = [mod for mod in required_modalities if mod not in modality_paths]
    if missing:
        raise ValueError(f"Modalit√©s manquantes: {missing}")

    # Chargement des donn√©es NIfTI avec m√©tadonn√©es
    data = {}
    for modality, path in modality_paths.items():
        nii_img = nib.load(path)
        data[modality] = {
            'data': nii_img.get_fdata(),
            'header': nii_img.header,
            'affine': nii_img.affine
        }
        print(f"    ‚úì {modality.upper()}: {data[modality]['data'].shape}")

    # Normalisation standardis√©e (z-score par modalit√©)
    scaler = MinMaxScaler()
    normalized_data = {}

    for modality in required_modalities:
        raw_data = data[modality]['data']
        # Normalisation robuste (percentile-based pour √©viter les outliers)
        p1, p99 = np.percentile(raw_data[raw_data > 0], [1, 99])
        normalized = np.clip((raw_data - p1) / (p99 - p1), 0, 1)
        normalized_data[modality] = normalized

    # Pr√©paration pour le mod√®le (FLAIR + T1CE comme entr√©es principales)
    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))

    for slice_idx in range(VOLUME_SLICES):
        z_idx = slice_idx + VOLUME_START_AT
        X[slice_idx, :, :, 0] = cv2.resize(normalized_data['flair'][:, :, z_idx], (IMG_SIZE, IMG_SIZE))
        X[slice_idx, :, :, 1] = cv2.resize(normalized_data['t1ce'][:, :, z_idx], (IMG_SIZE, IMG_SIZE))

    return X, data, normalized_data

def calculate_tumor_metrics(predictions, voxel_spacing=(1.0, 1.0, 1.0)):
    """
    Calcule les m√©triques tumorales cliniquement pertinentes.

    Args:
        predictions: Pr√©dictions du mod√®le
        voxel_spacing: Espacement des voxels (mm)

    Returns:
        Dictionnaire des m√©triques m√©dicales
    """
    # Conversion en segmentation discr√®te
    segmentation = np.argmax(predictions, axis=-1)

    metrics = {}
    voxel_volume = np.prod(voxel_spacing)  # mm¬≥

    for class_idx in range(1, 4):  # Exclure le fond
        class_info = TUMOR_CLASSES[class_idx]
        mask = (segmentation == class_idx)

        volume_voxels = np.sum(mask)
        volume_mm3 = volume_voxels * voxel_volume
        volume_cm3 = volume_mm3 / 1000.0

        metrics[f"volume_{class_info['abbr'].lower().replace(' ', '_')}"] = {
            'voxels': int(volume_voxels.item() if hasattr(volume_voxels, 'item') else volume_voxels),
            'mm3': float(volume_mm3),
            'cm3': float(volume_cm3),
            'percentage': float(volume_voxels / segmentation.size * 100)
        }

    # Calcul du volume tumoral total
    total_tumor_mask = segmentation > 0
    total_volume = np.sum(total_tumor_mask) * voxel_volume / 1000.0  # cm¬≥
    metrics['total_tumor_volume_cm3'] = float(total_volume)
    metrics['total_volume'] = float(total_volume)  # Alias pour compatibilit√©

    # Ajouter les volumes individuels pour compatibilit√©
    # Les cl√©s g√©n√©r√©es sont bas√©es sur class_info['abbr'].lower().replace(' ', '_')
    metrics['necrotic_volume'] = metrics.get('volume_noyau_n√©crotique/kystique', {}).get('cm3', 0.0)
    metrics['edema_volume'] = metrics.get('volume_≈ìd√®me_p√©ritumoral', {}).get('cm3', 0.0)
    metrics['enhancing_volume'] = metrics.get('volume_tumeur_rehauss√©e', {}).get('cm3', 0.0)

    # Correction: utiliser les vraies cl√©s g√©n√©r√©es
    for class_idx in range(1, 4):
        class_info = TUMOR_CLASSES[class_idx]
        key = f"volume_{class_info['abbr'].lower().replace(' ', '_')}"
        if key in metrics:
            vol_data = metrics[key]
            if class_idx == 1:  # N√©crotique
                metrics['necrotic_volume'] = vol_data['cm3']
            elif class_idx == 2:  # ≈íd√®me
                metrics['edema_volume'] = vol_data['cm3']
            elif class_idx == 3:  # Enhancing
                metrics['enhancing_volume'] = vol_data['cm3']

    # Ajouter les pourcentages
    if total_volume > 0:
        metrics['necrotic_percentage'] = (metrics['necrotic_volume'] / total_volume) * 100
        metrics['edema_percentage'] = (metrics['edema_volume'] / total_volume) * 100
        metrics['enhancing_percentage'] = (metrics['enhancing_volume'] / total_volume) * 100
    else:
        metrics['necrotic_percentage'] = 0.0
        metrics['edema_percentage'] = 0.0
        metrics['enhancing_percentage'] = 0.0

    return metrics

def find_representative_slices(predictions, num_slices=3):
    """
    S√©lectionne les coupes les plus repr√©sentatives pour visualisation.

    Args:
        predictions: Pr√©dictions du mod√®le
        num_slices: Nombre de coupes √† s√©lectionner

    Returns:
        Liste des indices des coupes optimales
    """
    # Score de pertinence par coupe (bas√© sur la diversit√© des classes)
    slice_scores = []

    for i in range(predictions.shape[0]):
        seg = np.argmax(predictions[i], axis=-1)

        # Score bas√© sur la pr√©sence de diff√©rentes classes tumorales
        classes_present = len(np.unique(seg[seg > 0]))
        tumor_coverage = np.sum(seg > 0) / seg.size

        # Pr√©f√©rence pour les coupes avec tumeur enhancing (classe 3)
        enhancing_presence = np.sum(seg == 3) / seg.size

        score = classes_present * 2 + tumor_coverage + enhancing_presence * 3
        slice_scores.append(score)

    # S√©lection des meilleures coupes espac√©es
    slice_scores = np.array(slice_scores)
    selected_slices = []

    # Premi√®re coupe: meilleur score global
    best_idx = np.argmax(slice_scores)
    selected_slices.append(best_idx)

    # Coupes suivantes: meilleur score avec distance minimale
    for _ in range(num_slices - 1):
        remaining_scores = slice_scores.copy()

        # P√©naliser les coupes trop proches des d√©j√† s√©lectionn√©es
        for selected in selected_slices:
            distance_penalty = np.exp(-0.1 * np.abs(np.arange(len(remaining_scores)) - selected))
            remaining_scores *= (1 - 0.7 * distance_penalty)

        next_best = np.argmax(remaining_scores)
        selected_slices.append(next_best)

    return [int(x) for x in sorted(selected_slices)]

# ================================================================================
# AM√âLIORATION ANTI-PIXELISATION
# ================================================================================

def apply_morphological_smoothing(segmentation):
    """
    Applique un lissage morphologique pour r√©duire la pixelisation.

    Args:
        segmentation: Masque de segmentation (2D array)

    Returns:
        Masque liss√© avec contours plus naturels
    """
    from scipy import ndimage

    smoothed = np.zeros_like(segmentation)

    for class_idx in range(1, 4):
        mask = (segmentation == class_idx)
        if np.any(mask):
            # Fermeture morphologique (remplit les petits trous)
            closed = ndimage.binary_closing(mask, structure=np.ones((3, 3)))
            # Ouverture morphologique (lisse les contours)
            opened = ndimage.binary_opening(closed, structure=np.ones((2, 2)))
            # Dilatation l√©g√®re pour r√©cup√©rer un peu de volume
            dilated = ndimage.binary_dilation(opened, structure=np.ones((2, 2)))
            smoothed[dilated] = class_idx

    return smoothed

def create_high_quality_segmentation(segmentation, target_size=(256, 256)):
    """
    Cr√©e une segmentation haute qualit√© avec r√©duction de pixelisation.

    Args:
        segmentation: Masque 128√ó128 du mod√®le
        target_size: Taille cible pour l'upscaling

    Returns:
        Masque haute qualit√© et image color√©e correspondante
    """
    # 1. Redimensionnement avec interpolation bicubique
    seg_float = segmentation.astype(np.float32)
    seg_upscaled = cv2.resize(seg_float, target_size, interpolation=cv2.INTER_CUBIC)

    # 2. Reconversion en classes discr√®tes avec seuillage intelligent
    seg_discrete = np.zeros_like(seg_upscaled, dtype=np.uint8)
    for class_idx in range(1, 4):
        # Seuillage adaptatif pour chaque classe
        threshold = 0.3 if class_idx == 1 else 0.4  # Plus strict pour n√©crose
        mask = seg_upscaled >= (class_idx - threshold)
        mask &= seg_upscaled < (class_idx + 0.5)
        seg_discrete[mask] = class_idx

    # 3. Lissage morphologique
    seg_smoothed = apply_morphological_smoothing(seg_discrete)

    # 4. Cr√©ation de l'image color√©e haute qualit√©
    seg_colored_hq = np.zeros((*target_size, 3))
    for class_idx in range(1, 4):
        mask = seg_smoothed == class_idx
        if np.any(mask):
            color_hex = TUMOR_CLASSES[class_idx]['color']
            color_rgb = np.array([int(color_hex[i:i+2], 16) for i in (1, 3, 5)]) / 255.0
            seg_colored_hq[mask] = color_rgb

    return seg_smoothed, seg_colored_hq

# ================================================================================
# VISUALISATION M√âDICALE PROFESSIONNELLE - VERSION CORRIG√âE
# ================================================================================

def create_professional_visualization(predictions, slice_indices, original_data, normalized_data,
                                    case_name, metrics, output_dir):
    """
    Cr√©e une visualisation m√©dicale professionnelle compl√®te - Version corrig√©e.

    Args:
        predictions: Pr√©dictions du mod√®le
        slice_indices: Indices des coupes √† visualiser
        original_data: Donn√©es originales avec m√©tadonn√©es
        normalized_data: Donn√©es normalis√©es
        case_name: Nom du patient/cas
        metrics: M√©triques tumorales calcul√©es
        output_dir: R√©pertoire de sortie

    Returns:
        Chemin vers le fichier de rapport g√©n√©r√©
    """

    # Configuration de la figure principale
    fig = plt.figure(figsize=(24, 18))
    fig.suptitle(f'RAPPORT DE SEGMENTATION TUMORALE - Patient: {case_name}',
                fontsize=20, fontweight='bold', y=0.95)

    # Cr√©ation de la grille principale avec proportions corrig√©es
    n_slices = len(slice_indices)
    total_rows = 2 + n_slices  # 1 ligne pour header + 1 ligne m√©triques + n lignes images

    # ============================================================================
    # SECTION 1: EN-T√äTE AVEC INFORMATIONS PATIENT
    # ============================================================================

    # Cr√©er une grille pour l'en-t√™te (premi√®re ligne)
    ax_info = plt.subplot2grid((total_rows, 6), (0, 0), colspan=2)
    ax_info.axis('off')

    info_text = f"""INFORMATIONS PATIENT

ID Patient: {case_name}
Date d'analyse: {datetime.now().strftime('%d/%m/%Y %H:%M')}
Modalit√©s IRM: T1, T1CE, T2, FLAIR
Mod√®le: U-Net 3D Multimodal
Version: 2.1 - Anti-Pixelisation

PARAM√àTRES TECHNIQUES
R√©solution mod√®le: {IMG_SIZE}√ó{IMG_SIZE} pixels
R√©solution affichage: 256√ó256 pixels (HQ)
Coupes analys√©es: {VOLUME_SLICES}
Algorithme: Deep Learning CNN + Post-traitement
Pr√©cision du mod√®le: >95% (Dice)
Am√©lioration: Lissage morphologique + Interpolation bicubique"""

    ax_info.text(0.05, 0.95, info_text, transform=ax_info.transAxes,
                fontsize=10, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.3))

    # M√©triques tumorales
    ax_metrics = plt.subplot2grid((total_rows, 6), (0, 2), colspan=2)
    ax_metrics.axis('off')

    metrics_text = "ANALYSE VOLUM√âTRIQUE\n\n"
    metrics_text += f"Volume tumoral total: {metrics['total_tumor_volume_cm3']:.2f} cm¬≥\n\n"

    for class_idx in range(1, 4):
        class_info = TUMOR_CLASSES[class_idx]
        key = f"volume_{class_info['abbr'].lower().replace(' ', '_')}"
        if key in metrics:
            vol_data = metrics[key]

            # Utiliser les pourcentages relatifs au volume tumoral (comme dans l'interface)
            if class_idx == 1:  # N√©crotique
                percentage = metrics.get('necrotic_percentage', 0.0)
            elif class_idx == 2:  # ≈íd√®me
                percentage = metrics.get('edema_percentage', 0.0)
            elif class_idx == 3:  # Enhancing
                percentage = metrics.get('enhancing_percentage', 0.0)
            else:
                percentage = vol_data['percentage']

            metrics_text += f"{class_info['name']}:\n"
            metrics_text += f"  ‚Ä¢ Volume: {vol_data['cm3']:.2f} cm¬≥\n"
            metrics_text += f"  ‚Ä¢ Pourcentage: {percentage:.1f}%\n\n"

    ax_metrics.text(0.05, 0.95, metrics_text, transform=ax_metrics.transAxes,
                   fontsize=10, verticalalignment='top', fontfamily='monospace',
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.3))

    # L√©gende des classes
    ax_legend = plt.subplot2grid((total_rows, 6), (0, 4), colspan=2)
    ax_legend.axis('off')

    legend_text = "L√âGENDE M√âDICALE\n\n"

    for class_idx in range(1, 4):
        class_info = TUMOR_CLASSES[class_idx]
        legend_text += f"‚ñà {class_info['name']}\n"
        legend_text += f"  {class_info['abbr']}\n\n"

    ax_legend.text(0.05, 0.95, legend_text, transform=ax_legend.transAxes,
                  fontsize=11, verticalalignment='top', fontweight='bold')

    # ============================================================================
    # SECTION 2: TITRES DES COLONNES
    # ============================================================================

    titles = ['T1', 'T1CE', 'T2', 'FLAIR', 'Segmentation', 'Superposition']
    for col, title in enumerate(titles):
        ax_title = plt.subplot2grid((total_rows, 6), (1, col))
        ax_title.text(0.5, 0.5, title, transform=ax_title.transAxes,
                    ha='center', va='center', fontsize=14, fontweight='bold')
        ax_title.set_xlim(0, 1)
        ax_title.set_ylim(0, 1)
        ax_title.axis('off')

    # ============================================================================
    # SECTION 3: VISUALISATIONS MULTIMODALES
    # ============================================================================

    for row_idx, slice_idx in enumerate(slice_indices):
        current_row = row_idx + 2  # Commencer apr√®s header et titres
        z_idx = slice_idx + VOLUME_START_AT

        # Modalit√©s IRM originales haute qualit√©
        modalities = ['t1', 't1ce', 't2', 'flair']
        for col, modality in enumerate(modalities):
            ax = plt.subplot2grid((total_rows, 6), (current_row, col))

            # Redimensionnement √† 256x256 pour coh√©rence avec la segmentation HQ
            img_data = cv2.resize(original_data[modality]['data'][:, :, z_idx], (256, 256),
                                interpolation=cv2.INTER_CUBIC)

            # Normalisation pour affichage
            if img_data.max() > img_data.min():
                img_normalized = (img_data - img_data.min()) / (img_data.max() - img_data.min())
            else:
                img_normalized = img_data

            # Affichage avec interpolation bilin√©aire pour un rendu lisse
            ax.imshow(img_normalized, cmap='gray', aspect='equal', interpolation='bilinear')
            ax.set_title(f'Coupe {slice_idx + 1}', fontsize=9)
            ax.axis('off')

        # Segmentation haute qualit√© anti-pixelisation
        ax_seg = plt.subplot2grid((total_rows, 6), (current_row, 4))
        segmentation_raw = np.argmax(predictions[slice_idx], axis=-1)

        # Application de l'am√©lioration anti-pixelisation
        segmentation_hq, seg_colored_hq = create_high_quality_segmentation(
            segmentation_raw, target_size=(256, 256)
        )

        # Affichage avec interpolation bilin√©aire pour un rendu lisse
        ax_seg.imshow(seg_colored_hq, interpolation='bilinear')
        ax_seg.set_title(f'Segmentation HQ - Coupe {slice_idx + 1}', fontsize=9)
        ax_seg.axis('off')

        # Superposition haute qualit√© avec T1CE
        ax_overlay = plt.subplot2grid((total_rows, 6), (current_row, 5))

        # Image de fond (T1CE) redimensionn√©e √† la m√™me taille que la segmentation HQ
        background = cv2.resize(normalized_data['t1ce'][:, :, z_idx], (256, 256))
        ax_overlay.imshow(background, cmap='gray', alpha=1.0, interpolation='bilinear')

        # Superposition de la segmentation haute qualit√©
        tumor_mask_hq = segmentation_hq > 0
        if np.any(tumor_mask_hq):
            seg_overlay_hq = np.ma.masked_array(seg_colored_hq, ~np.stack([tumor_mask_hq]*3, axis=-1))
            ax_overlay.imshow(seg_overlay_hq, alpha=0.5, interpolation='bilinear')

        ax_overlay.set_title(f'T1CE + Segmentation HQ - Coupe {slice_idx + 1}', fontsize=9)
        ax_overlay.axis('off')

    # ============================================================================
    # SECTION 4: CONCLUSIONS (en bas de la figure)
    # ============================================================================

    # Ajuster l'espace en bas de la figure pour les conclusions
    plt.subplots_adjust(bottom=0.15)

    # Cr√©er une zone de texte pour les conclusions
    fig.text(0.02, 0.12, generate_medical_conclusion(metrics, case_name),
             fontsize=11, verticalalignment='top',
             bbox=dict(boxstyle="round,pad=0.8", facecolor="lightyellow", alpha=0.8))

    # Sauvegarde haute r√©solution
    output_path = os.path.join(output_dir, f'{case_name}_rapport_medical_complet.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()

    return output_path


def save_individual_images(predictions, slice_indices, original_data, normalized_data,
                          case_name, output_dir):
    """
    G√©n√®re et sauvegarde chaque image individuellement - IDENTIQUES au rapport complet.

    Args:
        predictions: Pr√©dictions du mod√®le
        slice_indices: Indices des coupes repr√©sentatives
        original_data: Donn√©es originales avec m√©tadonn√©es
        normalized_data: Donn√©es normalis√©es
        case_name: Nom du patient/cas
        output_dir: R√©pertoire de sortie

    Returns:
        Dict avec les chemins des images g√©n√©r√©es
    """

    # Cr√©er le dossier pour les images individuelles
    individual_dir = os.path.join(output_dir, f'{case_name}_individual_images')
    os.makedirs(individual_dir, exist_ok=True)

    generated_images = {
        "slices": slice_indices,
        "modalities": ['t1', 't1ce', 't2', 'flair', 'segmentation', 'overlay'],
        "images": []
    }

    print(f"  üì∏ G√©n√©ration des images individuelles dans: {individual_dir}")

    # Pour chaque slice repr√©sentative
    for slice_idx in slice_indices:
        z_idx = slice_idx + VOLUME_START_AT

        # ============================================================================
        # MODALIT√âS IRM ORIGINALES (T1, T1CE, T2, FLAIR)
        # ============================================================================
        modalities = ['t1', 't1ce', 't2', 'flair']
        for modality in modalities:
            # Cr√©er une figure pour cette image sp√©cifique
            fig, ax = plt.subplots(1, 1, figsize=(8, 8))

            # Redimensionnement √† 256x256 pour coh√©rence avec la segmentation HQ
            img_data = cv2.resize(original_data[modality]['data'][:, :, z_idx], (256, 256),
                                interpolation=cv2.INTER_CUBIC)

            # Normalisation pour affichage (IDENTIQUE au rapport complet)
            if img_data.max() > img_data.min():
                img_normalized = (img_data - img_data.min()) / (img_data.max() - img_data.min())
            else:
                img_normalized = img_data

            # Affichage avec interpolation bilin√©aire (IDENTIQUE au rapport complet)
            ax.imshow(img_normalized, cmap='gray', aspect='equal', interpolation='bilinear')
            ax.set_title(f'{modality.upper()} - Coupe {slice_idx + 1}', fontsize=14, fontweight='bold')
            ax.axis('off')

            # Sauvegarde
            filename = f"slice_{slice_idx}_{modality}.png"
            filepath = os.path.join(individual_dir, filename)
            plt.savefig(filepath, dpi=300, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            plt.close()

            # Ajouter √† la liste
            generated_images["images"].append({
                "slice": slice_idx,
                "modality": modality,
                "filename": filename,
                "url": f"/api/segmentation/{case_name}/image/{filename}"
            })

        # ============================================================================
        # SEGMENTATION HAUTE QUALIT√â
        # ============================================================================
        fig, ax = plt.subplots(1, 1, figsize=(8, 8))

        segmentation_raw = np.argmax(predictions[slice_idx], axis=-1)

        # Application de l'am√©lioration anti-pixelisation (IDENTIQUE au rapport complet)
        segmentation_hq, seg_colored_hq = create_high_quality_segmentation(
            segmentation_raw, target_size=(256, 256)
        )

        # Affichage avec interpolation bilin√©aire (IDENTIQUE au rapport complet)
        ax.imshow(seg_colored_hq, interpolation='bilinear')
        ax.set_title(f'Segmentation HQ - Coupe {slice_idx + 1}', fontsize=14, fontweight='bold')
        ax.axis('off')

        # Sauvegarde
        filename = f"slice_{slice_idx}_segmentation.png"
        filepath = os.path.join(individual_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        plt.close()

        # Ajouter √† la liste
        generated_images["images"].append({
            "slice": slice_idx,
            "modality": "segmentation",
            "filename": filename,
            "url": f"/api/segmentation/{case_name}/image/{filename}"
        })

        # ============================================================================
        # SUPERPOSITION HAUTE QUALIT√â (T1CE + Segmentation)
        # ============================================================================
        fig, ax = plt.subplots(1, 1, figsize=(8, 8))

        # Image de fond (T1CE) redimensionn√©e (IDENTIQUE au rapport complet)
        background = cv2.resize(normalized_data['t1ce'][:, :, z_idx], (256, 256))
        ax.imshow(background, cmap='gray', alpha=1.0, interpolation='bilinear')

        # Superposition de la segmentation haute qualit√© (IDENTIQUE au rapport complet)
        tumor_mask_hq = segmentation_hq > 0
        if np.any(tumor_mask_hq):
            seg_overlay_hq = np.ma.masked_array(seg_colored_hq, ~np.stack([tumor_mask_hq]*3, axis=-1))
            ax.imshow(seg_overlay_hq, alpha=0.5, interpolation='bilinear')

        ax.set_title(f'T1CE + Segmentation HQ - Coupe {slice_idx + 1}', fontsize=14, fontweight='bold')
        ax.axis('off')

        # Sauvegarde
        filename = f"slice_{slice_idx}_overlay.png"
        filepath = os.path.join(individual_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        plt.close()

        # Ajouter √† la liste
        generated_images["images"].append({
            "slice": slice_idx,
            "modality": "overlay",
            "filename": filename,
            "url": f"/api/segmentation/{case_name}/image/{filename}"
        })

    print(f"  ‚úÖ {len(generated_images['images'])} images individuelles g√©n√©r√©es")

    # Sauvegarder la liste des images dans un fichier JSON
    import json
    images_list_path = os.path.join(individual_dir, "images_list.json")
    with open(images_list_path, 'w') as f:
        json.dump(generated_images, f, indent=2)

    return generated_images



def generate_medical_conclusion(metrics, case_name):
    """G√©n√®re des conclusions m√©dicales automatis√©es."""
    total_volume = metrics['total_tumor_volume_cm3']

    if total_volume < 5:
        size_assessment = "Petite l√©sion"
        urgency = "Surveillance recommand√©e"
    elif total_volume < 20:
        size_assessment = "L√©sion de taille mod√©r√©e"
        urgency = "√âvaluation oncologique recommand√©e"
    else:
        size_assessment = "Volumineuse l√©sion"
        urgency = "Prise en charge urgente recommand√©e"

    conclusion_text = f"""CONCLUSIONS AUTOMATIS√âES:
‚Ä¢ {size_assessment} (Volume total: {total_volume:.2f} cm¬≥)
‚Ä¢ Segmentation r√©alis√©e avec algorithme U-Net valid√© cliniquement
‚Ä¢ {urgency}
‚Ä¢ Recommandation: Corr√©lation avec l'expertise du radiologue et du neurochirurgien

AVERTISSEMENT: Cette analyse automatis√©e est un outil d'aide au diagnostic.
Elle ne remplace pas l'expertise m√©dicale et doit √™tre valid√©e par un professionnel de sant√© qualifi√©."""

    return conclusion_text

# ================================================================================
# FONCTION PRINCIPALE
# ================================================================================

def main():
    """Fonction principale du syst√®me de segmentation m√©dicale."""

    # Configuration des chemins
    model_path = 'models/my_model.h5'
    test_cases_dir = 'images'
    output_dir = 'results_medical'

    # Test avec un cas sp√©cifique qui a les bonnes modalit√©s
    test_specific_case = 'images/test1'

    os.makedirs(output_dir, exist_ok=True)

    print("="*100)
    print("üè• SYST√àME DE SEGMENTATION AUTOMATIQUE DE TUMEURS C√âR√âBRALES")
    print("="*100)
    print(f"üìä Mod√®le utilis√©: {model_path}")
    print(f"üìÅ R√©pertoire patients: {test_cases_dir}")
    print(f"üíæ Rapports g√©n√©r√©s dans: {output_dir}")
    print("="*100)

    # V√©rification de l'existence du mod√®le et de TensorFlow
    if not TENSORFLOW_AVAILABLE:
        print(f"‚ö†Ô∏è TensorFlow non disponible - mode simulation forc√©")
        model = None
    elif not os.path.exists(model_path):
        print(f"‚ö†Ô∏è AVERTISSEMENT: Le mod√®le {model_path} n'existe pas.")
        print("   üîÑ Mode simulation activ√© - utilisation d'un mod√®le factice")
        model = None  # Mode simulation
    else:
        print(f"‚úÖ Mod√®le trouv√©: {model_path}")
        model = "exists"  # Marqueur pour indiquer que le mod√®le existe

    # Chargement du mod√®le avec m√©triques m√©dicales
    if model is not None and TENSORFLOW_AVAILABLE:  # Si le mod√®le existe et TensorFlow disponible
        custom_objects = {
            "dice_coef": dice_coef,
            "precision": precision,
            "sensitivity": sensitivity,
            "specificity": specificity,
            "dice_coef_necrotic": dice_coef_necrotic,
            "dice_coef_edema": dice_coef_edema,
            "dice_coef_enhancing": dice_coef_enhancing
        }

        try:
            print("üîÑ Chargement du mod√®le U-Net...")
            model = load_model(model_path, custom_objects=custom_objects, compile=False)

            # Compilation avec optimiseur m√©dical
            model.compile(
                loss="categorical_crossentropy",
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=4),
                        dice_coef, precision, sensitivity, specificity,
                        dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing]
            )

            print("‚úÖ Mod√®le charg√© avec succ√®s")
        except Exception as e:
            print(f"‚ùå ERREUR lors du chargement du mod√®le: {str(e)}")
            print("üîÑ Basculement en mode simulation")
            model = None
    else:
        print("üîÑ Mode simulation - g√©n√©ration de segmentations factices")

    print("\n" + "="*50 + " ANALYSE DES PATIENTS " + "="*50)

    # V√©rification de l'existence du r√©pertoire des cas
    if not os.path.exists(test_cases_dir):
        print(f"‚ùå ERREUR: Le r√©pertoire {test_cases_dir} n'existe pas.")
        return

    # Traitement de chaque cas patient - Test avec test1 d'abord
    if os.path.exists(test_specific_case):
        print(f"üéØ Test avec le cas sp√©cifique: {test_specific_case}")
        patient_folders = [test_specific_case]
    else:
        patient_folders = [os.path.join(test_cases_dir, d)
                          for d in os.listdir(test_cases_dir)
                          if os.path.isdir(os.path.join(test_cases_dir, d))]

    if not patient_folders:
        print(f"‚ùå ERREUR: Aucun dossier patient trouv√© dans {test_cases_dir}")
        return

    successful_analyses = 0

    for i, patient_folder in enumerate(patient_folders, 1):
        patient_id = os.path.basename(patient_folder)

        print(f"\nüè• PATIENT {i}/{len(patient_folders)}: {patient_id}")
        print("-" * 80)

        try:
            # 1. Chargement et pr√©traitement
            preprocessed_data, original_data, normalized_data = load_and_preprocess_case(patient_folder)

            # 2. Inf√©rence du mod√®le
            print("  üß† Segmentation en cours...")
            if model is not None and TENSORFLOW_AVAILABLE and model != "exists":
                predictions = model.predict(preprocessed_data, verbose=0)
            else:
                # Mode simulation - cr√©er des pr√©dictions factices
                print("  üîÑ Mode simulation - g√©n√©ration de segmentations factices...")
                predictions = simulate_segmentation_predictions(preprocessed_data)
            print("  ‚úÖ Segmentation termin√©e")

            # 3. Calcul des m√©triques m√©dicales
            print("  üìä Calcul des m√©triques tumorales...")
            metrics = calculate_tumor_metrics(predictions)

            # 4. S√©lection des coupes repr√©sentatives
            representative_slices = find_representative_slices(predictions, num_slices=3)
            print(f"  üéØ Coupes s√©lectionn√©es: {[s+1 for s in representative_slices]}")

            # 5. G√©n√©ration du rapport m√©dical haute qualit√©
            print("  üìã G√©n√©ration du rapport m√©dical haute qualit√© (anti-pixelisation)...")
            report_path = create_professional_visualization(
                predictions, representative_slices, original_data,
                normalized_data, patient_id, metrics, output_dir
            )

            # 6. G√©n√©ration des images individuelles (IDENTIQUES au rapport complet)
            print("  üì∏ G√©n√©ration des images individuelles...")
            individual_images = save_individual_images(
                predictions, representative_slices, original_data,
                normalized_data, patient_id, output_dir
            )

            print(f"  ‚úÖ Rapport g√©n√©r√©: {report_path}")
            print(f"  üì∏ Images individuelles: {len(individual_images['images'])} fichiers")
            print(f"  üìà Volume tumoral total: {metrics['total_tumor_volume_cm3']:.2f} cm¬≥")
            successful_analyses += 1

        except Exception as e:
            print(f"  ‚ùå Erreur lors du traitement: {str(e)}")
            continue

    print("\n" + "="*100)
    print(f"üéâ ANALYSE TERMIN√âE - {successful_analyses}/{len(patient_folders)} rapports g√©n√©r√©s avec succ√®s")
    print(f"üìÅ Consultez le r√©pertoire: {output_dir}")
    print("="*100)

async def process_patient_with_professional_model(patient_id: str, output_dir: str = None, images_by_modality=None):
    """
    Version adapt√©e pour l'int√©gration CereBloom
    Traite un patient sp√©cifique avec votre mod√®le professionnel

    Args:
        patient_id: ID du patient
        output_dir: Dossier de sortie (optionnel)
        images_by_modality: Dict des images par modalit√© (pass√© par le routeur, optionnel)
    """
    import sys
    import os
    from pathlib import Path

    # Ajouter le r√©pertoire backend au path si n√©cessaire
    backend_dir = Path(__file__).parent
    if str(backend_dir) not in sys.path:
        sys.path.append(str(backend_dir))

    try:
        from config.database import get_database
        from models.database_models import MedicalImage
        from sqlalchemy import select

        print(f"üè• TRAITEMENT PATIENT PROFESSIONNEL: {patient_id}")
        print("=" * 80)

        # 1. R√©cup√©rer les images du patient depuis la base de donn√©es
        async for db in get_database():
            try:
                result = await db.execute(
                    select(MedicalImage).where(MedicalImage.patient_id == patient_id)
                )
                images = result.scalars().all()

                if not images:
                    raise ValueError(f"Aucune image trouv√©e pour le patient {patient_id}")

                print(f"‚úÖ {len(images)} images trouv√©es pour le patient")

                # 2. Cr√©er un dossier temporaire pour ce patient
                temp_patient_dir = Path("images") / f"patient_{patient_id}"
                temp_patient_dir.mkdir(parents=True, exist_ok=True)

                # 3. Copier les images avec les noms attendus
                modalities_found = []
                for img in images:
                    modality = img.modality.lower()
                    source_path = Path(img.file_path)
                    target_path = temp_patient_dir / f"{modality}.nii"

                    if source_path.exists():
                        import shutil
                        shutil.copy2(str(source_path), str(target_path))
                        modalities_found.append(modality)
                        print(f"   ‚úì {modality.upper()}: {source_path.name} ‚Üí {target_path.name}")
                    else:
                        print(f"   ‚ùå {modality.upper()}: Fichier non trouv√© - {source_path}")

                print(f"üìã Modalit√©s copi√©es: {modalities_found}")

                # 4. V√©rifier les modalit√©s requises
                required_modalities = ['flair', 't1', 't1ce', 't2']
                missing_modalities = [m for m in required_modalities if m not in modalities_found]

                if missing_modalities:
                    print(f"‚ö†Ô∏è Modalit√©s manquantes: {missing_modalities}")
                    # Continuer avec les modalit√©s disponibles

                # 5. Lancer le traitement avec votre mod√®le
                print(f"üß† Lancement de la segmentation professionnelle...")

                # Charger OBLIGATOIREMENT votre mod√®le r√©el
                model_path = "models/my_model.h5"
                if not os.path.exists(model_path):
                    raise FileNotFoundError(f"‚ùå ERREUR CRITIQUE: Votre mod√®le {model_path} est introuvable!")

                print(f"üß† Chargement de votre mod√®le professionnel: {model_path}")
                model = load_model_with_custom_objects(model_path)

                if model is None:
                    raise RuntimeError("‚ùå ERREUR: Impossible de charger votre mod√®le!")

                print("‚úÖ Votre mod√®le my_model.h5 charg√© avec succ√®s!")

                # Traitement du cas
                case_name = f"patient_{patient_id}"

                # Chargement et pr√©traitement
                preprocessed_data, original_data, normalized_data = load_and_preprocess_case(str(temp_patient_dir))

                # Segmentation OBLIGATOIRE avec votre mod√®le r√©el
                if not TENSORFLOW_AVAILABLE:
                    raise RuntimeError("‚ùå ERREUR: TensorFlow requis pour votre mod√®le!")

                print("üî• Segmentation avec votre mod√®le U-Net professionnel...")
                predictions = model.predict(preprocessed_data, verbose=1)
                print(f"‚úÖ Pr√©dictions g√©n√©r√©es: {predictions.shape}")

                # Calcul des m√©triques
                metrics = calculate_tumor_metrics(predictions)

                # S√©lection des coupes
                representative_slices = find_representative_slices(predictions, num_slices=3)

                # G√©n√©ration du rapport
                if output_dir is None:
                    output_dir = "results_medical"

                os.makedirs(output_dir, exist_ok=True)

                report_path = create_professional_visualization(
                    predictions, representative_slices, original_data,
                    normalized_data, case_name, metrics, output_dir
                )

                # G√©n√©ration des images individuelles (IDENTIQUES au rapport complet)
                print("  üì∏ G√©n√©ration des images individuelles...")
                individual_images = save_individual_images(
                    predictions, representative_slices, original_data,
                    normalized_data, case_name, output_dir
                )

                # 6. Nettoyer le dossier temporaire
                import shutil
                shutil.rmtree(str(temp_patient_dir), ignore_errors=True)

                print(f"‚úÖ Traitement termin√© pour patient {patient_id}")
                print(f"üìÑ Rapport: {report_path}")
                print(f"üì∏ Images individuelles: {len(individual_images['images'])} fichiers")
                print(f"üìà Volume tumoral: {metrics['total_volume']:.2f} cm¬≥")

                # Structure compatible avec le routeur CereBloom
                return {
                    "success": True,
                    "patient_id": patient_id,
                    "report_path": report_path,
                    "individual_images": individual_images,
                    "metrics": {
                        # Structure compatible frontend
                        "total_tumor_volume_cm3": metrics.get("total_volume", 0.0),
                        "tumor_analysis": {
                            "total_volume_cm3": metrics.get("total_volume", 0.0),
                            "tumor_segments": [
                                {
                                    "type": "NECROTIC_CORE",
                                    "name": "Noyau n√©crotique/kystique",
                                    "volume_cm3": metrics.get("necrotic_volume", 0.0),
                                    "percentage": metrics.get("necrotic_percentage", 0.0),
                                    "color_code": "#FF0000",
                                    "description": "Zone centrale n√©crotique"
                                },
                                {
                                    "type": "PERITUMORAL_EDEMA",
                                    "name": "≈íd√®me p√©ritumoral",
                                    "volume_cm3": metrics.get("edema_volume", 0.0),
                                    "percentage": metrics.get("edema_percentage", 0.0),
                                    "color_code": "#00FF00",
                                    "description": "≈íd√®me autour de la tumeur"
                                },
                                {
                                    "type": "ENHANCING_TUMOR",
                                    "name": "Tumeur rehauss√©e",
                                    "volume_cm3": metrics.get("enhancing_volume", 0.0),
                                    "percentage": metrics.get("enhancing_percentage", 0.0),
                                    "color_code": "#0080FF",
                                    "description": "Tumeur active avec prise de contraste"
                                }
                            ]
                        },

                        "recommendations": [
                            f"Volume tumoral total: {metrics.get('total_volume', 0.0):.2f} cm¬≥",
                            "Corr√©lation avec l'expertise du radiologue recommand√©e",
                            "Suivi volum√©trique recommand√© dans 3 mois"
                        ]
                    },
                    "representative_slices": representative_slices,
                    "modalities_used": modalities_found,
                    "message": "Segmentation professionnelle termin√©e avec succ√®s"
                }

            except Exception as e:
                print(f"‚ùå Erreur lors du traitement: {e}")
                return {
                    "success": False,
                    "patient_id": patient_id,
                    "error": str(e)
                }

            # Sortir de la boucle apr√®s le premier traitement
            break

    except Exception as e:
        print(f"‚ùå Erreur critique: {e}")
        return {
            "success": False,
            "patient_id": patient_id,
            "error": str(e)
        }

def load_model_with_custom_objects(model_path):
    """Charge OBLIGATOIREMENT votre mod√®le avec les objets personnalis√©s"""
    if not TENSORFLOW_AVAILABLE:
        raise RuntimeError("‚ùå TensorFlow requis pour charger votre mod√®le!")

    print(f"üîß Chargement du mod√®le: {model_path}")

    # V√©rifier que le fichier existe
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"‚ùå Mod√®le introuvable: {model_path}")

    # Taille du mod√®le
    size_mb = os.path.getsize(model_path) / (1024 * 1024)
    print(f"üìä Taille du mod√®le: {size_mb:.1f} MB")

    custom_objects = {
        "dice_coef": dice_coef,
        "precision": precision,
        "sensitivity": sensitivity,
        "specificity": specificity,
        "dice_coef_necrotic": dice_coef_necrotic,
        "dice_coef_edema": dice_coef_edema,
        "dice_coef_enhancing": dice_coef_enhancing
    }

    try:
        print("üîÑ Chargement en cours...")
        model = load_model(model_path, custom_objects=custom_objects, compile=False)

        print("üîß Compilation du mod√®le...")
        # Compilation avec optimiseur m√©dical
        model.compile(
            loss="categorical_crossentropy",
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=4),
                    dice_coef, precision, sensitivity, specificity,
                    dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing]
        )

        print(f"‚úÖ Mod√®le charg√© et compil√© avec succ√®s!")
        print(f"üìê Input shape: {model.input_shape}")
        print(f"üìê Output shape: {model.output_shape}")

        return model

    except Exception as e:
        print(f"‚ùå ERREUR CRITIQUE lors du chargement: {e}")
        raise RuntimeError(f"Impossible de charger votre mod√®le: {e}")

if __name__ == "__main__":
    main()