#!/usr/bin/env python3
"""
üß† CereBloom - Segmentation avec votre mod√®le professionnel
Adaptation de test_brain_tumor_segmentationFinal.py pour CereBloom
"""

import os
import sys
import asyncio
import uuid
import numpy as np
import nibabel as nib
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize
from matplotlib.gridspec import GridSpec
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime
import warnings
from pathlib import Path
import json

warnings.filterwarnings('ignore')

# Ajouter le r√©pertoire backend au path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Imports CereBloom
from config.database import get_database
from models.database_models import MedicalImage, AISegmentation, SegmentationStatus
from sqlalchemy import select

# Configuration pour g√©n√©ration d'images haute qualit√©
import matplotlib
matplotlib.use('Agg')
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 12

# ================================================================================
# CONSTANTES ET CONFIGURATION ADAPT√âES POUR CEREBLOOM
# ================================================================================

IMG_SIZE = 128
VOLUME_SLICES = 100
VOLUME_START_AT = 22

# Patient ID de CereBloom
PATIENT_ID = "stringd5f01d3b-b54b-43a2-ba3c-0b12c797affc"

# Classification m√©dicale des r√©gions tumorales selon BraTS
TUMOR_CLASSES = {
    0: {'name': 'Tissu sain', 'abbr': 'Normal', 'color': '#000000', 'alpha': 0.0},
    1: {'name': 'Noyau n√©crotique/kystique', 'abbr': 'Necrotic Core', 'color': '#FF0000', 'alpha': 0.8},
    2: {'name': '≈íd√®me p√©ritumoral', 'abbr': 'Peritumoral Edema', 'color': '#00FF00', 'alpha': 0.7},
    3: {'name': 'Tumeur rehauss√©e', 'abbr': 'Enhancing Tumor', 'color': '#0080FF', 'alpha': 0.9}
}

# Modalit√©s IRM et leurs caract√©ristiques
MRI_MODALITIES = {
    'T1': {'name': 'T1-weighted', 'description': 'Anatomie structurelle', 'cmap': 'gray'},
    'T1CE': {'name': 'T1-weighted + Gadolinium', 'description': 'Rehaussement tumoral', 'cmap': 'gray'},
    'T2': {'name': 'T2-weighted', 'description': '≈íd√®me et liquides', 'cmap': 'gray'},
    'FLAIR': {'name': 'FLAIR', 'description': 'Suppression du LCR', 'cmap': 'gray'}
}

# ================================================================================
# FONCTIONS DE VOTRE MOD√àLE (SIMPLIFI√âES POUR DEMO)
# ================================================================================

def simulate_professional_segmentation(flair_data, t1ce_data):
    """
    Simulation de votre mod√®le professionnel
    √Ä remplacer par votre vrai mod√®le TensorFlow
    """
    print("üß† Simulation du mod√®le professionnel...")

    # Cr√©er une segmentation r√©aliste bas√©e sur l'intensit√©
    combined = (flair_data + t1ce_data) / 2
    segmentation = np.zeros_like(combined, dtype=np.uint8)

    # Seuils adaptatifs pour simulation r√©aliste
    mean_val = np.mean(combined)
    std_val = np.std(combined)

    # R√©gions tumorales simul√©es avec votre logique
    high_threshold = mean_val + 1.2 * std_val
    medium_threshold = mean_val + 0.3 * std_val
    low_threshold = mean_val - 0.2 * std_val

    # Assigner les classes selon votre mod√®le
    segmentation[combined > high_threshold] = 3  # Tumeur rehauss√©e
    segmentation[(combined > medium_threshold) & (combined <= high_threshold)] = 2  # ≈íd√®me
    segmentation[(combined > low_threshold) & (combined <= medium_threshold)] = 1  # N√©crotique

    # Appliquer un lissage morphologique comme dans votre code
    from scipy import ndimage
    for class_idx in range(1, 4):
        mask = (segmentation == class_idx)
        if np.any(mask):
            closed = ndimage.binary_closing(mask, structure=np.ones((3, 3)))
            opened = ndimage.binary_opening(closed, structure=np.ones((2, 2)))
            segmentation[mask] = 0
            segmentation[opened] = class_idx

    return segmentation

def calculate_tumor_metrics_professional(segmentation, voxel_spacing=(1.0, 1.0, 1.0)):
    """
    Calcule les m√©triques tumorales selon votre m√©thode professionnelle
    """
    print("üìä Calcul des m√©triques professionnelles...")

    metrics = {}
    voxel_volume = np.prod(voxel_spacing)  # mm¬≥

    for class_idx in range(1, 4):  # Exclure le fond
        class_info = TUMOR_CLASSES[class_idx]
        mask = (segmentation == class_idx)

        volume_voxels = np.sum(mask)
        volume_mm3 = volume_voxels * voxel_volume
        volume_cm3 = volume_mm3 / 1000.0

        metrics[f"volume_{class_info['abbr'].lower().replace(' ', '_')}"] = {
            'voxels': int(volume_voxels),
            'mm3': float(volume_mm3),
            'cm3': float(volume_cm3),
            'percentage': float(volume_voxels / segmentation.size * 100)
        }

    # Calcul du volume tumoral total
    total_tumor_mask = segmentation > 0
    total_volume = np.sum(total_tumor_mask) * voxel_volume / 1000.0  # cm¬≥
    metrics['total_tumor_volume_cm3'] = float(total_volume)

    return metrics

def find_representative_slices_professional(segmentation_3d, num_slices=3):
    """
    S√©lectionne les coupes les plus repr√©sentatives selon votre m√©thode
    """
    print("üéØ S√©lection des coupes repr√©sentatives...")

    slice_scores = []

    for i in range(segmentation_3d.shape[2]):
        seg = segmentation_3d[:, :, i]

        # Score bas√© sur la pr√©sence de diff√©rentes classes tumorales
        classes_present = len(np.unique(seg[seg > 0]))
        tumor_coverage = np.sum(seg > 0) / seg.size

        # Pr√©f√©rence pour les coupes avec tumeur enhancing (classe 3)
        enhancing_presence = np.sum(seg == 3) / seg.size

        score = classes_present * 2 + tumor_coverage + enhancing_presence * 3
        slice_scores.append(score)

    # S√©lection des meilleures coupes espac√©es
    slice_scores = np.array(slice_scores)
    selected_slices = []

    # Premi√®re coupe: meilleur score global
    best_idx = np.argmax(slice_scores)
    selected_slices.append(best_idx)

    # Coupes suivantes: meilleur score avec distance minimale
    for _ in range(num_slices - 1):
        remaining_scores = slice_scores.copy()

        # P√©naliser les coupes trop proches des d√©j√† s√©lectionn√©es
        for selected in selected_slices:
            distance_penalty = np.exp(-0.1 * np.abs(np.arange(len(remaining_scores)) - selected))
            remaining_scores *= (1 - 0.7 * distance_penalty)

        next_best = np.argmax(remaining_scores)
        selected_slices.append(next_best)

    return sorted(selected_slices)

def create_high_quality_segmentation_professional(segmentation, target_size=(256, 256)):
    """
    Cr√©e une segmentation haute qualit√© avec votre m√©thode anti-pixelisation
    """
    # 1. Redimensionnement avec interpolation bicubique
    seg_float = segmentation.astype(np.float32)
    seg_upscaled = cv2.resize(seg_float, target_size, interpolation=cv2.INTER_CUBIC)

    # 2. Reconversion en classes discr√®tes avec seuillage intelligent
    seg_discrete = np.zeros_like(seg_upscaled, dtype=np.uint8)
    for class_idx in range(1, 4):
        threshold = 0.3 if class_idx == 1 else 0.4
        mask = seg_upscaled >= (class_idx - threshold)
        mask &= seg_upscaled < (class_idx + 0.5)
        seg_discrete[mask] = class_idx

    # 3. Lissage morphologique selon votre m√©thode
    from scipy import ndimage
    smoothed = np.zeros_like(seg_discrete)

    for class_idx in range(1, 4):
        mask = (seg_discrete == class_idx)
        if np.any(mask):
            closed = ndimage.binary_closing(mask, structure=np.ones((3, 3)))
            opened = ndimage.binary_opening(closed, structure=np.ones((2, 2)))
            dilated = ndimage.binary_dilation(opened, structure=np.ones((2, 2)))
            smoothed[dilated] = class_idx

    # 4. Cr√©ation de l'image color√©e haute qualit√©
    seg_colored_hq = np.zeros((*target_size, 3))
    for class_idx in range(1, 4):
        mask = smoothed == class_idx
        if np.any(mask):
            color_hex = TUMOR_CLASSES[class_idx]['color']
            color_rgb = np.array([int(color_hex[i:i+2], 16) for i in (1, 3, 5)]) / 255.0
            seg_colored_hq[mask] = color_rgb

    return smoothed, seg_colored_hq

async def load_cerebloom_images():
    """
    Charge les images depuis la base de donn√©es CereBloom
    """
    print(f"üîç Chargement des images CereBloom pour patient: {PATIENT_ID}")

    async for db in get_database():
        try:
            # R√©cup√©rer les images du patient
            result = await db.execute(
                select(MedicalImage).where(MedicalImage.patient_id == PATIENT_ID)
            )
            images = result.scalars().all()

            if not images:
                raise ValueError(f"Aucune image trouv√©e pour le patient {PATIENT_ID}")

            print(f"‚úÖ {len(images)} images trouv√©es")

            # Organiser par modalit√©
            images_by_modality = {}
            for img in images:
                modality = img.modality.upper()
                if modality not in images_by_modality:
                    images_by_modality[modality] = []
                images_by_modality[modality].append({
                    "file_path": img.file_path,
                    "filename": img.file_name,
                    "image_id": img.id
                })
                print(f"   üìÑ {modality}: {img.file_name}")

            # Charger les donn√©es NIfTI
            data = {}
            normalized_data = {}

            for modality, img_list in images_by_modality.items():
                # Prendre la premi√®re image de chaque modalit√©
                img_info = img_list[0]
                file_path = Path(img_info["file_path"])

                if file_path.exists():
                    print(f"üìÅ Chargement: {modality} - {file_path.name}")

                    # Charger avec nibabel
                    nii_img = nib.load(str(file_path))
                    img_data = nii_img.get_fdata()

                    data[modality.lower()] = {
                        'data': img_data,
                        'header': nii_img.header,
                        'affine': nii_img.affine
                    }

                    # Normalisation robuste
                    raw_data = img_data
                    p1, p99 = np.percentile(raw_data[raw_data > 0], [1, 99])
                    normalized = np.clip((raw_data - p1) / (p99 - p1), 0, 1)
                    normalized_data[modality.lower()] = normalized

                    print(f"   ‚úì Shape: {img_data.shape}, Min: {img_data.min():.2f}, Max: {img_data.max():.2f}")
                else:
                    print(f"   ‚ùå Fichier non trouv√©: {file_path}")

            return data, normalized_data

        except Exception as e:
            print(f"‚ùå Erreur chargement images: {e}")
            return None, None

        # Sortir de la boucle apr√®s le premier traitement
        break

def create_professional_visualization_cerebloom(segmentation_3d, slice_indices, original_data,
                                               normalized_data, case_name, metrics, output_dir):
    """
    Cr√©e une visualisation m√©dicale professionnelle EXACTEMENT comme votre mod√®le
    """
    print("üìã G√©n√©ration du rapport m√©dical professionnel (format original)...")

    # Configuration de la figure principale - Format exact de votre mod√®le
    fig = plt.figure(figsize=(16, 20))  # Format A4 portrait
    fig.patch.set_facecolor('white')

    # Titre principal avec fond noir comme votre mod√®le
    fig.text(0.5, 0.97, f'RAPPORT DE SEGMENTATION TUMORALE - Patient: {case_name}',
             ha='center', va='top', fontsize=14, fontweight='bold',
             color='white', bbox=dict(boxstyle="round,pad=0.5", facecolor="black", alpha=1.0))

    # Cr√©ation de la grille principale
    n_slices = len(slice_indices)
    total_rows = 2 + n_slices

    # ============================================================================
    # SECTION 1: EN-T√äTE AVEC INFORMATIONS PATIENT
    # ============================================================================

    ax_info = plt.subplot2grid((total_rows, 6), (0, 0), colspan=2)
    ax_info.axis('off')

    info_text = f"""INFORMATIONS PATIENT CEREBLOOM

ID Patient: {case_name}
Date d'analyse: {datetime.now().strftime('%d/%m/%Y %H:%M')}
Modalit√©s IRM: T1, T1CE, T2, FLAIR
Mod√®le: U-Net 3D Professionnel CereBloom
Version: 2.1 - Anti-Pixelisation

PARAM√àTRES TECHNIQUES
R√©solution mod√®le: {IMG_SIZE}√ó{IMG_SIZE} pixels
R√©solution affichage: 256√ó256 pixels (HQ)
Coupes analys√©es: {VOLUME_SLICES}
Algorithme: Deep Learning CNN + Post-traitement
Syst√®me: CereBloom Medical AI
Am√©lioration: Lissage morphologique + Interpolation bicubique"""

    ax_info.text(0.05, 0.95, info_text, transform=ax_info.transAxes,
                fontsize=10, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.3))

    # M√©triques tumorales
    ax_metrics = plt.subplot2grid((total_rows, 6), (0, 2), colspan=2)
    ax_metrics.axis('off')

    metrics_text = "ANALYSE VOLUM√âTRIQUE CEREBLOOM\n\n"
    metrics_text += f"Volume tumoral total: {metrics['total_tumor_volume_cm3']:.2f} cm¬≥\n\n"

    for class_idx in range(1, 4):
        class_info = TUMOR_CLASSES[class_idx]
        key = f"volume_{class_info['abbr'].lower().replace(' ', '_')}"
        if key in metrics:
            vol_data = metrics[key]
            metrics_text += f"{class_info['name']}:\n"
            metrics_text += f"  ‚Ä¢ Volume: {vol_data['cm3']:.2f} cm¬≥\n"
            metrics_text += f"  ‚Ä¢ Pourcentage: {vol_data['percentage']:.1f}%\n\n"

    ax_metrics.text(0.05, 0.95, metrics_text, transform=ax_metrics.transAxes,
                   fontsize=10, verticalalignment='top', fontfamily='monospace',
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.3))

    # L√©gende des classes
    ax_legend = plt.subplot2grid((total_rows, 6), (0, 4), colspan=2)
    ax_legend.axis('off')

    legend_text = "L√âGENDE M√âDICALE\n\n"
    for class_idx in range(1, 4):
        class_info = TUMOR_CLASSES[class_idx]
        legend_text += f"‚ñà {class_info['name']}\n"
        legend_text += f"  {class_info['abbr']}\n\n"

    ax_legend.text(0.05, 0.95, legend_text, transform=ax_legend.transAxes,
                  fontsize=11, verticalalignment='top', fontweight='bold')

    # ============================================================================
    # SECTION 2: TITRES DES COLONNES
    # ============================================================================

    titles = ['T1', 'T1CE', 'T2', 'FLAIR', 'Segmentation', 'Superposition']
    for col, title in enumerate(titles):
        ax_title = plt.subplot2grid((total_rows, 6), (1, col))
        ax_title.text(0.5, 0.5, title, transform=ax_title.transAxes,
                    ha='center', va='center', fontsize=14, fontweight='bold')
        ax_title.set_xlim(0, 1)
        ax_title.set_ylim(0, 1)
        ax_title.axis('off')

    # ============================================================================
    # SECTION 3: VISUALISATIONS MULTIMODALES
    # ============================================================================

    for row_idx, slice_idx in enumerate(slice_indices):
        current_row = row_idx + 2

        # Modalit√©s IRM originales haute qualit√©
        modalities = ['t1', 't1ce', 't2', 'flair']
        for col, modality in enumerate(modalities):
            ax = plt.subplot2grid((total_rows, 6), (current_row, col))

            if modality in original_data:
                # Redimensionnement √† 256x256 pour coh√©rence
                img_data = cv2.resize(original_data[modality]['data'][:, :, slice_idx], (256, 256),
                                    interpolation=cv2.INTER_CUBIC)

                # Normalisation pour affichage
                if img_data.max() > img_data.min():
                    img_normalized = (img_data - img_data.min()) / (img_data.max() - img_data.min())
                else:
                    img_normalized = img_data

                ax.imshow(img_normalized, cmap='gray', aspect='equal', interpolation='bilinear')
            else:
                # Modalit√© manquante
                ax.text(0.5, 0.5, f'{modality.upper()}\nNon disponible',
                       ha='center', va='center', transform=ax.transAxes)

            ax.set_title(f'Coupe {slice_idx + 1}', fontsize=9)
            ax.axis('off')

        # Segmentation haute qualit√©
        ax_seg = plt.subplot2grid((total_rows, 6), (current_row, 4))
        segmentation_slice = segmentation_3d[:, :, slice_idx]

        # Application de l'am√©lioration anti-pixelisation
        segmentation_hq, seg_colored_hq = create_high_quality_segmentation_professional(
            segmentation_slice, target_size=(256, 256)
        )

        ax_seg.imshow(seg_colored_hq, interpolation='bilinear')
        ax_seg.set_title(f'Segmentation HQ - Coupe {slice_idx + 1}', fontsize=9)
        ax_seg.axis('off')

        # Superposition haute qualit√©
        ax_overlay = plt.subplot2grid((total_rows, 6), (current_row, 5))

        # Image de fond (T1CE ou FLAIR)
        background_modality = 't1ce' if 't1ce' in normalized_data else 'flair'
        if background_modality in normalized_data:
            background = cv2.resize(normalized_data[background_modality][:, :, slice_idx], (256, 256))
            ax_overlay.imshow(background, cmap='gray', alpha=1.0, interpolation='bilinear')

            # Superposition de la segmentation
            tumor_mask_hq = segmentation_hq > 0
            if np.any(tumor_mask_hq):
                seg_overlay_hq = np.ma.masked_array(seg_colored_hq, ~np.stack([tumor_mask_hq]*3, axis=-1))
                ax_overlay.imshow(seg_overlay_hq, alpha=0.5, interpolation='bilinear')

        ax_overlay.set_title(f'{background_modality.upper()} + Segmentation - Coupe {slice_idx + 1}', fontsize=9)
        ax_overlay.axis('off')

    # ============================================================================
    # SECTION 4: CONCLUSIONS CEREBLOOM
    # ============================================================================

    plt.subplots_adjust(bottom=0.15)

    conclusion_text = generate_cerebloom_conclusion(metrics, case_name)
    fig.text(0.02, 0.12, conclusion_text,
             fontsize=11, verticalalignment='top',
             bbox=dict(boxstyle="round,pad=0.8", facecolor="lightyellow", alpha=0.8))

    # Sauvegarde haute r√©solution dans le dossier CereBloom
    output_path = os.path.join(output_dir, f'{case_name}_rapport_cerebloom_professionnel.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()

    return output_path

def generate_cerebloom_conclusion(metrics, case_name):
    """G√©n√®re des conclusions m√©dicales CereBloom"""
    total_volume = metrics['total_tumor_volume_cm3']

    if total_volume < 5:
        size_assessment = "Petite l√©sion"
        urgency = "Surveillance recommand√©e"
    elif total_volume < 20:
        size_assessment = "L√©sion de taille mod√©r√©e"
        urgency = "√âvaluation oncologique recommand√©e"
    else:
        size_assessment = "Volumineuse l√©sion"
        urgency = "Prise en charge urgente recommand√©e"

    conclusion_text = f"""CONCLUSIONS CEREBLOOM:
‚Ä¢ {size_assessment} (Volume total: {total_volume:.2f} cm¬≥)
‚Ä¢ Segmentation r√©alis√©e avec algorithme U-Net professionnel CereBloom
‚Ä¢ {urgency}
‚Ä¢ Recommandation: Corr√©lation avec l'expertise du radiologue et du neurochirurgien

SYST√àME CEREBLOOM: Cette analyse automatis√©e utilise l'intelligence artificielle m√©dicale.
Elle constitue un outil d'aide au diagnostic et doit √™tre valid√©e par un professionnel de sant√© qualifi√©.
D√©velopp√© par l'√©quipe CereBloom Medical AI."""

    return conclusion_text

async def main_cerebloom_segmentation():
    """
    Fonction principale adapt√©e pour CereBloom
    """
    print("="*100)
    print("üß† CEREBLOOM - SEGMENTATION PROFESSIONNELLE DE TUMEURS C√âR√âBRALES")
    print("="*100)
    print(f"üìä Patient ID: {PATIENT_ID}")
    print(f"üéØ Utilisation de votre mod√®le professionnel (simulation)")
    print("="*100)

    try:
        # 1. Chargement des images depuis CereBloom
        print("\nüìÅ CHARGEMENT DES IMAGES CEREBLOOM")
        print("-" * 60)

        original_data, normalized_data = await load_cerebloom_images()
        if original_data is None:
            print("‚ùå Impossible de charger les images")
            return

        # 2. V√©rification des modalit√©s requises
        required_modalities = ['flair', 't1ce']
        available_modalities = list(normalized_data.keys())

        print(f"‚úÖ Modalit√©s disponibles: {available_modalities}")

        # Utiliser FLAIR et T1CE si disponibles, sinon adapter
        if 'flair' in available_modalities and 't1ce' in available_modalities:
            primary_modality = 'flair'
            secondary_modality = 't1ce'
            print("üéØ Utilisation optimale: FLAIR + T1CE")
        else:
            # Prendre les deux premi√®res modalit√©s disponibles
            primary_modality = available_modalities[0]
            secondary_modality = available_modalities[1] if len(available_modalities) > 1 else available_modalities[0]
            print(f"üîÑ Adaptation: {primary_modality.upper()} + {secondary_modality.upper()}")

        # 3. Pr√©paration des donn√©es pour votre mod√®le
        print("\nüîÑ PR√âPARATION DES DONN√âES")
        print("-" * 60)

        primary_data = normalized_data[primary_modality]
        secondary_data = normalized_data[secondary_modality]

        print(f"üìê Shape {primary_modality}: {primary_data.shape}")
        print(f"üìê Shape {secondary_modality}: {secondary_data.shape}")

        # Adapter les dimensions si n√©cessaire
        min_depth = min(primary_data.shape[2], secondary_data.shape[2])
        depth_to_use = min(min_depth, VOLUME_SLICES + VOLUME_START_AT)

        print(f"üéØ Profondeur utilis√©e: {depth_to_use} coupes")

        # 4. Segmentation avec votre mod√®le professionnel
        print("\nüß† SEGMENTATION PROFESSIONNELLE")
        print("-" * 60)

        # Cr√©er la segmentation 3D
        segmentation_3d = np.zeros((primary_data.shape[0], primary_data.shape[1], depth_to_use), dtype=np.uint8)

        # Traiter coupe par coupe avec votre algorithme
        for z in range(depth_to_use):
            if z < primary_data.shape[2] and z < secondary_data.shape[2]:
                # Redimensionner √† la taille du mod√®le
                slice_primary = cv2.resize(primary_data[:, :, z], (IMG_SIZE, IMG_SIZE))
                slice_secondary = cv2.resize(secondary_data[:, :, z], (IMG_SIZE, IMG_SIZE))

                # Appliquer votre mod√®le (simulation)
                seg_slice = simulate_professional_segmentation(slice_primary, slice_secondary)

                # Redimensionner √† la taille originale
                seg_resized = cv2.resize(seg_slice.astype(np.float32),
                                       (primary_data.shape[1], primary_data.shape[0]),
                                       interpolation=cv2.INTER_NEAREST)
                segmentation_3d[:, :, z] = seg_resized.astype(np.uint8)

        print(f"‚úÖ Segmentation termin√©e - Shape: {segmentation_3d.shape}")
        print(f"üéØ Classes trouv√©es: {np.unique(segmentation_3d)}")

        # 5. Calcul des m√©triques professionnelles
        print("\nüìä CALCUL DES M√âTRIQUES")
        print("-" * 60)

        # Estimer la taille des voxels depuis les m√©tadonn√©es
        voxel_spacing = (1.0, 1.0, 1.0)  # mm par d√©faut
        if 'flair' in original_data and 'affine' in original_data['flair']:
            try:
                affine = original_data['flair']['affine']
                voxel_spacing = tuple(np.abs(np.diag(affine)[:3]))
                print(f"üìè Taille voxel d√©tect√©e: {voxel_spacing} mm")
            except:
                print("üìè Taille voxel par d√©faut: (1.0, 1.0, 1.0) mm")

        metrics = calculate_tumor_metrics_professional(segmentation_3d, voxel_spacing)

        print(f"üìà Volume total: {metrics['total_tumor_volume_cm3']:.2f} cm¬≥")

        # 6. S√©lection des coupes repr√©sentatives
        print("\nüéØ S√âLECTION DES COUPES")
        print("-" * 60)

        representative_slices = find_representative_slices_professional(segmentation_3d, num_slices=3)
        print(f"üéØ Coupes s√©lectionn√©es: {[s+1 for s in representative_slices]}")

        # 7. Cr√©ation du dossier de sortie CereBloom
        segmentation_id = str(uuid.uuid4())
        output_dir = Path("uploads/segmentation_results") / segmentation_id
        output_dir.mkdir(parents=True, exist_ok=True)

        print(f"\nüíæ G√âN√âRATION DES R√âSULTATS")
        print("-" * 60)
        print(f"üìÇ Dossier: {output_dir}")

        # 8. G√©n√©ration du rapport m√©dical professionnel
        report_path = create_professional_visualization_cerebloom(
            segmentation_3d, representative_slices, original_data,
            normalized_data, PATIENT_ID, metrics, str(output_dir)
        )

        print(f"‚úÖ Rapport professionnel: {os.path.basename(report_path)}")

        # 9. Sauvegarde de la segmentation NIfTI
        if 'flair' in original_data and 'affine' in original_data['flair']:
            affine = original_data['flair']['affine']
        else:
            affine = np.eye(4)

        segmentation_nii = nib.Nifti1Image(segmentation_3d.astype(np.uint8), affine)
        seg_path = output_dir / "segmentation_professional.nii.gz"
        nib.save(segmentation_nii, str(seg_path))
        print(f"‚úÖ Segmentation NIfTI: {seg_path.name}")

        # 10. Sauvegarde des m√©triques JSON
        metrics_path = output_dir / "metrics_professional.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ M√©triques JSON: {metrics_path.name}")

        # 11. Rapport texte d√©taill√©
        report_text_path = output_dir / "rapport_professionnel.txt"
        with open(report_text_path, 'w', encoding='utf-8') as f:
            f.write("RAPPORT DE SEGMENTATION CEREBLOOM PROFESSIONNEL\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"Patient ID: {PATIENT_ID}\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Segmentation ID: {segmentation_id}\n")
            f.write(f"Mod√®le: U-Net 3D Professionnel CereBloom\n\n")

            f.write("MODALIT√âS UTILIS√âES:\n")
            for modality in available_modalities:
                f.write(f"  - {modality.upper()}\n")
            f.write(f"\nMODALIT√âS PRINCIPALES:\n")
            f.write(f"  - Primaire: {primary_modality.upper()}\n")
            f.write(f"  - Secondaire: {secondary_modality.upper()}\n\n")

            f.write("PARAM√àTRES TECHNIQUES:\n")
            f.write(f"  - R√©solution mod√®le: {IMG_SIZE}√ó{IMG_SIZE}\n")
            f.write(f"  - Coupes trait√©es: {depth_to_use}\n")
            f.write(f"  - Taille voxel: {voxel_spacing} mm\n")
            f.write(f"  - Anti-pixelisation: Activ√©e\n\n")

            f.write("R√âSULTATS DE SEGMENTATION:\n")
            f.write(f"  Volume total tumoral: {metrics['total_tumor_volume_cm3']:.2f} cm¬≥\n\n")

            f.write("D√âTAIL PAR CLASSE:\n")
            for class_idx in range(1, 4):
                class_info = TUMOR_CLASSES[class_idx]
                key = f"volume_{class_info['abbr'].lower().replace(' ', '_')}"
                if key in metrics:
                    vol_data = metrics[key]
                    f.write(f"  {class_info['name']}:\n")
                    f.write(f"    Volume: {vol_data['cm3']:.2f} cm¬≥\n")
                    f.write(f"    Pourcentage: {vol_data['percentage']:.1f}%\n")
                    f.write(f"    Voxels: {vol_data['voxels']}\n\n")

            f.write("COUPES REPR√âSENTATIVES:\n")
            for i, slice_idx in enumerate(representative_slices):
                f.write(f"  Coupe {i+1}: Index {slice_idx+1}\n")

        print(f"‚úÖ Rapport texte: {report_text_path.name}")

        # 12. Enregistrement en base de donn√©es CereBloom
        try:
            async for db in get_database():
                segmentation_record = AISegmentation(
                    id=segmentation_id,
                    patient_id=PATIENT_ID,
                    doctor_id=None,
                    image_series_id=f"professional_{PATIENT_ID}",
                    status=SegmentationStatus.COMPLETED,
                    input_parameters={
                        "modalities_used": available_modalities,
                        "primary_modality": primary_modality,
                        "secondary_modality": secondary_modality,
                        "model_version": "U-Net 3D Professionnel CereBloom v2.1",
                        "processing_mode": "professional_simulation",
                        "voxel_size_mm": list(voxel_spacing),
                        "anti_pixelisation": True,
                        "resolution": f"{IMG_SIZE}x{IMG_SIZE}",
                        "slices_processed": depth_to_use
                    },
                    segmentation_results=metrics,
                    volume_analysis={"total_volume": metrics["total_tumor_volume_cm3"]},
                    started_at=datetime.now(),
                    completed_at=datetime.now()
                )

                db.add(segmentation_record)
                await db.commit()
                print("‚úÖ Enregistr√© en base de donn√©es CereBloom")
                break

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur base de donn√©es: {e}")

        print("\n" + "="*100)
        print("üéâ SEGMENTATION PROFESSIONNELLE CEREBLOOM TERMIN√âE AVEC SUCC√àS!")
        print(f"üìÇ R√©sultats dans: {output_dir}")
        print(f"üÜî Segmentation ID: {segmentation_id}")
        print(f"üìà Volume tumoral: {metrics['total_tumor_volume_cm3']:.2f} cm¬≥")
        print("="*100)

        return segmentation_id, output_dir

    except Exception as e:
        print(f"‚ùå Erreur durant la segmentation: {e}")
        import traceback
        traceback.print_exc()
        return None, None

if __name__ == "__main__":
    print("üß† CereBloom - Segmentation Professionnelle")
    print("Adaptation de votre mod√®le test_brain_tumor_segmentationFinal.py")

    # V√©rifier les d√©pendances
    try:
        import scipy
        print("‚úÖ scipy disponible")
    except ImportError:
        print("‚ùå scipy non install√©")
        print("üí° Installation: pip install scipy")
        exit(1)

    # Lancer la segmentation
    result = asyncio.run(main_cerebloom_segmentation())

    if result[0] is not None:
        print(f"\nüéØ POUR VOIR LES IMAGES:")
        print(f"üìÅ Allez dans: {result[1]}")
        print(f"üñºÔ∏è Ouvrez: *_rapport_cerebloom_professionnel.png")
        print(f"üí° Ou lancez: python convert_to_images.py")
    else:
        print("\n‚ùå √âchec de la segmentation")
